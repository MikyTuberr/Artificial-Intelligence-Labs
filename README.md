# Laboratory 1: Regression

## Overview
In this lab, we focus on linear regression, a fundamental technique in machine learning. Linear regression aims to find a linear relationship between input features and an outcome variable. We explore the concepts of linear regression, data splitting, cost functions, gradient descent, and standardization.

## Linear Regression
Linear regression involves finding a linear function to predict an outcome variable based on input features. The model parameters are optimized to minimize the error between predicted and actual values.

## Data Splitting
Datasets are divided into training and testing sets to train the model on one subset and evaluate its performance on another. This prevents overfitting and provides a measure of generalization.

## Cost Function
The cost function quantifies the difference between predicted and actual values. Mean squared error (MSE) is a common choice for regression problems.

## Gradient Descent
Gradient descent is an iterative optimization algorithm used to minimize the cost function. It adjusts model parameters in the direction of steepest descent of the cost function.

## Standardization
Standardization is a preprocessing step where input features are scaled to have a mean of 0 and a standard deviation of 1. This ensures that features are on a similar scale, facilitating the training process.

